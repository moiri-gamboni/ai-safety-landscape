{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Database Conversion: SQLite to PostgreSQL\n",
    "This notebook converts the SQLite database to PostgreSQL format while preserving:\n",
    "- Schema structure\n",
    "- Data integrity\n",
    "- Relationships\n",
    "- Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if running in Colab\n",
    "import os\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    # Install PostgreSQL in Colab environment\n",
    "    !sudo apt-get -qq update && sudo apt-get -qq install postgresql postgresql-contrib # pyright: ignore\n",
    "    !sudo service postgresql start # pyright: ignore\n",
    "    \n",
    "    # Configure PostgreSQL to allow passwordless access\n",
    "    !sudo sed -i 's/local\\s*all\\s*postgres\\s*peer/local all postgres trust/' /etc/postgresql/14/main/pg_hba.conf # pyright: ignore\n",
    "    !sudo service postgresql restart # pyright: ignore\n",
    "    \n",
    "    # Install Python client\n",
    "    %pip install psycopg2-binary tqdm # pyright: ignore\n",
    "\n",
    "# Mount Google Drive\n",
    "from google.colab import drive # pyright: ignore [reportMissingImports]\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 2. Database Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# @title Database Credentials\n",
    "postgres_db = \"postgres\" # @param {type:\"string\"} (using default database)\n",
    "postgres_user = \"postgres\" # @param {type:\"string\"}\n",
    "\n",
    "import sqlite3\n",
    "import psycopg2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Path to SQLite database\n",
    "sqlite_path = \"/content/drive/MyDrive/ai-safety-papers/papers.db\"\n",
    "\n",
    "# Connect to SQLite\n",
    "sqlite_conn = sqlite3.connect(sqlite_path)\n",
    "sqlite_conn.row_factory = sqlite3.Row\n",
    "\n",
    "\n",
    "# Connect to default postgres database\n",
    "postgres_conn = psycopg2.connect(\n",
    "    host='',\n",
    "    database=postgres_db,\n",
    "    user=postgres_user\n",
    ")\n",
    "postgres_conn.autocommit = False\n",
    "pg_cursor = postgres_conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 3. Schema Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_postgres_schema(pg_cursor):\n",
    "    \"\"\"Create PostgreSQL schema matching SQLite structure\"\"\"\n",
    "    try:\n",
    "        # Create tables with PostgreSQL data types\n",
    "        pg_cursor.execute('''\n",
    "            CREATE TABLE papers (\n",
    "                id TEXT PRIMARY KEY,\n",
    "                title TEXT,\n",
    "                abstract TEXT,\n",
    "                categories TEXT,\n",
    "                msc_class TEXT,\n",
    "                acm_class TEXT,\n",
    "                doi TEXT,\n",
    "                license TEXT,\n",
    "                comments TEXT,\n",
    "                created TIMESTAMP,\n",
    "                updated TIMESTAMP,\n",
    "                withdrawn BOOLEAN DEFAULT FALSE,\n",
    "                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                abstract_embedding BYTEA\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        pg_cursor.execute('''\n",
    "            CREATE TABLE paper_versions (\n",
    "                paper_id TEXT,\n",
    "                version INTEGER,\n",
    "                source_type TEXT,\n",
    "                size TEXT,\n",
    "                date TIMESTAMP,\n",
    "                PRIMARY KEY (paper_id, version),\n",
    "                FOREIGN KEY (paper_id) REFERENCES papers(id)\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        pg_cursor.execute('''\n",
    "            CREATE TABLE authors (\n",
    "                id SERIAL PRIMARY KEY,\n",
    "                keyname TEXT NOT NULL,\n",
    "                forenames TEXT,\n",
    "                suffix TEXT,\n",
    "                CONSTRAINT unique_author UNIQUE (keyname, forenames, suffix)\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        pg_cursor.execute('''\n",
    "            CREATE TABLE paper_authors (\n",
    "                paper_id TEXT,\n",
    "                author_id INTEGER,\n",
    "                author_position INTEGER,\n",
    "                PRIMARY KEY (paper_id, author_id),\n",
    "                FOREIGN KEY (paper_id) REFERENCES papers(id),\n",
    "                FOREIGN KEY (author_id) REFERENCES authors(id)\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        # Create indexes\n",
    "        pg_cursor.execute('CREATE INDEX idx_categories ON papers(categories)')\n",
    "        pg_cursor.execute('CREATE INDEX idx_withdrawn ON papers(withdrawn)')\n",
    "        pg_cursor.execute('CREATE INDEX idx_created ON papers(created)')\n",
    "        pg_cursor.execute('CREATE INDEX idx_updated ON papers(updated)')\n",
    "        \n",
    "        print(\"PostgreSQL schema created successfully\")\n",
    "        \n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"Error creating schema: {e}\")\n",
    "        postgres_conn.rollback()\n",
    "        raise\n",
    "\n",
    "# Create PostgreSQL schema\n",
    "create_postgres_schema(pg_cursor)\n",
    "postgres_conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 4. Data Migration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def migrate_table(sqlite_conn, pg_cursor, table_name, columns, batch_size=1000):\n",
    "    \"\"\"Migrate data from SQLite to PostgreSQL with batch processing\"\"\"\n",
    "    # Get total count for progress bar\n",
    "    sqlite_cur = sqlite_conn.cursor()\n",
    "    sqlite_cur.execute(f'SELECT COUNT(*) FROM {table_name}')\n",
    "    total_rows = sqlite_cur.fetchone()[0]\n",
    "    \n",
    "    # Get data in batches\n",
    "    offset = 0\n",
    "    with tqdm(total=total_rows, desc=f\"Migrating {table_name}\", unit=\"rows\") as pbar:\n",
    "        while True:\n",
    "            sqlite_cur.execute(f'SELECT * FROM {table_name} LIMIT ? OFFSET ?', (batch_size, offset))\n",
    "            batch = sqlite_cur.fetchall()\n",
    "            if not batch:\n",
    "                break\n",
    "                \n",
    "            # Convert SQLite rows to PostgreSQL compatible format\n",
    "            rows = []\n",
    "            for row in batch:\n",
    "                row_data = []\n",
    "                for col in columns:\n",
    "                    value = row[col]\n",
    "                    # Convert SQLite boolean (0/1) to Python bool\n",
    "                    if col == 'withdrawn' and value is not None:\n",
    "                        value = bool(value)\n",
    "                    # Handle numpy arrays for embeddings\n",
    "                    if col == 'abstract_embedding' and value is not None:\n",
    "                        value = psycopg2.Binary(value)\n",
    "                    row_data.append(value)\n",
    "                rows.append(tuple(row_data))\n",
    "            \n",
    "            # Generate INSERT query\n",
    "            placeholders = ','.join(['%s'] * len(columns))\n",
    "            columns_str = ','.join([f'\"{col}\"' for col in columns])\n",
    "            query = f'INSERT INTO {table_name} ({columns_str}) VALUES ({placeholders})'\n",
    "            \n",
    "            try:\n",
    "                pg_cursor.executemany(query, rows)\n",
    "                postgres_conn.commit()\n",
    "            except psycopg2.Error as e:\n",
    "                print(f\"Error inserting batch: {e}\")\n",
    "                postgres_conn.rollback()\n",
    "                raise\n",
    "                \n",
    "            offset += len(batch)\n",
    "            pbar.update(len(batch))\n",
    "\n",
    "# Migration order respecting foreign key constraints\n",
    "tables = [\n",
    "    ('papers', ['id', 'title', 'abstract', 'categories', 'msc_class', 'acm_class',\n",
    "                'doi', 'license', 'comments', 'created', 'updated', 'withdrawn',\n",
    "                'created_at', 'abstract_embedding']),\n",
    "    ('authors', ['id', 'keyname', 'forenames', 'suffix']),\n",
    "    ('paper_versions', ['paper_id', 'version', 'source_type', 'size', 'date']),\n",
    "    ('paper_authors', ['paper_id', 'author_id', 'author_position'])\n",
    "]\n",
    "\n",
    "# Disable foreign key constraints during migration\n",
    "pg_cursor.execute('SET CONSTRAINTS ALL DEFERRED')\n",
    "\n",
    "# Migrate tables\n",
    "for table_name, columns in tables:\n",
    "    migrate_table(sqlite_conn, pg_cursor, table_name, columns)\n",
    "\n",
    "# Reset sequence for authors table\n",
    "pg_cursor.execute(\"SELECT setval('authors_id_seq', (SELECT MAX(id) FROM authors))\")\n",
    "postgres_conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 5. Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def validate_migration(sqlite_conn, postgres_conn):\n",
    "    \"\"\"Validate table counts and sample data between databases\"\"\"\n",
    "    tables = ['papers', 'authors', 'paper_versions', 'paper_authors']\n",
    "    \n",
    "    for table in tables:\n",
    "        # Get SQLite count\n",
    "        sqlite_cur = sqlite_conn.cursor()\n",
    "        sqlite_cur.execute(f'SELECT COUNT(*) FROM {table}')\n",
    "        sqlite_count = sqlite_cur.fetchone()[0]\n",
    "        \n",
    "        # Get PostgreSQL count\n",
    "        pg_cur = postgres_conn.cursor()\n",
    "        pg_cur.execute(f'SELECT COUNT(*) FROM {table}')\n",
    "        pg_count = pg_cur.fetchone()[0]\n",
    "        \n",
    "        print(f\"{table}:\")\n",
    "        print(f\"  SQLite: {sqlite_count}\")\n",
    "        print(f\"  PostgreSQL: {pg_count}\")\n",
    "        print(f\"  Match: {sqlite_count == pg_count}\\n\")\n",
    "        \n",
    "    # Check sample data\n",
    "    print(\"\\nSample Data Validation:\")\n",
    "    pg_cur.execute('''\n",
    "        SELECT p.id, p.title, COUNT(a.id) as author_count\n",
    "        FROM papers p\n",
    "        JOIN paper_authors pa ON p.id = pa.paper_id\n",
    "        JOIN authors a ON pa.author_id = a.id\n",
    "        GROUP BY p.id\n",
    "        LIMIT 5\n",
    "    ''')\n",
    "    print(\"PostgreSQL sample papers with author counts:\")\n",
    "    for row in pg_cur.fetchall():\n",
    "        print(f\"ID: {row[0]}, Authors: {row[2]}\")\n",
    "        \n",
    "    sqlite_cur.execute('''\n",
    "        SELECT p.id, p.title, COUNT(a.id) as author_count\n",
    "        FROM papers p\n",
    "        JOIN paper_authors pa ON p.id = pa.paper_id\n",
    "        JOIN authors a ON pa.author_id = a.id\n",
    "        GROUP BY p.id\n",
    "        LIMIT 5\n",
    "    ''')\n",
    "    print(\"\\nSQLite sample papers with author counts:\")\n",
    "    for row in sqlite_cur.fetchall():\n",
    "        print(f\"ID: {row[0]}, Authors: {row[2]}\")\n",
    "\n",
    "validate_migration(sqlite_conn, postgres_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 6. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## 7. PostgreSQL Backup to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backup_postgres_db():\n",
    "    \"\"\"Backup PostgreSQL database to Google Drive\"\"\"\n",
    "    backup_path = \"/content/drive/MyDrive/ai-safety-papers/postgres_backup.sql\"\n",
    "    \n",
    "    print(f\"Creating PostgreSQL backup at {backup_path}\")\n",
    "    \n",
    "    # Updated dump command for default database\n",
    "    !pg_dump -h localhost -U postgres -F c -f {backup_path}\n",
    "    \n",
    "    print(\"Backup completed successfully\")\n",
    "\n",
    "# Backup after successful migration\n",
    "backup_postgres_db()\n",
    "\n",
    "# Close connections\n",
    "sqlite_conn.close()\n",
    "postgres_conn.close()\n",
    "\n",
    "print(\"Database conversion and backup completed successfully\") "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
