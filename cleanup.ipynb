{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# AI Safety Papers Visualization - Cleanup (should not be needed after fixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Load Existing Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Check if database exists in Drive\n",
    "db_path = \"/content/drive/MyDrive/ai-safety-papers/papers.db\"\n",
    "if os.path.exists(db_path):\n",
    "    print(f\"Found existing database at {db_path}\")\n",
    "    !cp \"{db_path}\" papers.db\n",
    "    \n",
    "    # Print existing data summary\n",
    "    conn = sqlite3.connect('papers.db')\n",
    "    c = conn.cursor()\n",
    "    c.execute('SELECT COUNT(*) FROM papers')\n",
    "    print(f\"Database contains {c.fetchone()[0]} papers\")\n",
    "else:\n",
    "    print(\"No existing database found in Drive. Will create new one.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Clean Up Author Duplicates\n",
    "Run this cell to deduplicate authors and fix the database schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_authors(conn):\n",
    "    \"\"\"Clean up duplicate authors and add proper constraints\"\"\"\n",
    "    c = conn.cursor()\n",
    "    print(\"Starting author cleanup...\")\n",
    "    \n",
    "    try:\n",
    "        # Start transaction\n",
    "        c.execute('BEGIN TRANSACTION')\n",
    "        \n",
    "        # Create temporary table for canonical authors with pre-computed normalized values\n",
    "        print(\"Creating canonical authors table...\")\n",
    "        c.execute('DROP TABLE IF EXISTS canonical_authors')\n",
    "        c.execute('''\n",
    "            CREATE TABLE canonical_authors AS\n",
    "            SELECT \n",
    "                MIN(id) as canonical_id,\n",
    "                keyname,\n",
    "                forenames,\n",
    "                CASE \n",
    "                    WHEN suffix IS NOT NULL AND UPPER(suffix) IN ('JR', 'JR.', 'JR ', 'JUNIOR') THEN 'Jr.'\n",
    "                    WHEN suffix IS NOT NULL AND UPPER(suffix) IN ('I', 'II', 'III', 'IV', 'V') THEN UPPER(suffix)\n",
    "                    ELSE suffix\n",
    "                END as suffix,\n",
    "                COALESCE(forenames, '') as forenames_clean,\n",
    "                COALESCE(\n",
    "                    CASE \n",
    "                        WHEN suffix IS NOT NULL AND UPPER(suffix) IN ('JR', 'JR.', 'JR ', 'JUNIOR') THEN 'Jr.'\n",
    "                        WHEN suffix IS NOT NULL AND UPPER(suffix) IN ('I', 'II', 'III', 'IV', 'V') THEN UPPER(suffix)\n",
    "                        ELSE suffix\n",
    "                    END,\n",
    "                    ''\n",
    "                ) as suffix_clean\n",
    "            FROM authors\n",
    "            GROUP BY \n",
    "                keyname, \n",
    "                forenames,\n",
    "                CASE \n",
    "                    WHEN suffix IS NOT NULL AND UPPER(suffix) IN ('JR', 'JR.', 'JR ', 'JUNIOR') THEN 'Jr.'\n",
    "                    WHEN suffix IS NOT NULL AND UPPER(suffix) IN ('I', 'II', 'III', 'IV', 'V') THEN UPPER(suffix)\n",
    "                    ELSE suffix\n",
    "                END\n",
    "        ''')\n",
    "        \n",
    "        # Create indices for faster joins using normalized columns\n",
    "        print(\"Creating indices for mapping...\")\n",
    "        c.execute('CREATE INDEX idx_canonical_lookup ON canonical_authors(keyname, forenames_clean, suffix_clean)')\n",
    "        c.execute('CREATE INDEX idx_authors_lookup ON authors(keyname)')\n",
    "        \n",
    "        # Create mapping table with proper schema\n",
    "        print(\"Creating author ID mapping table...\")\n",
    "        c.execute('DROP TABLE IF EXISTS author_id_mapping')\n",
    "        c.execute('''\n",
    "            CREATE TABLE author_id_mapping (\n",
    "                old_id INTEGER PRIMARY KEY,\n",
    "                new_id INTEGER NOT NULL\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        # Process authors in batches with pre-computed normalized values\n",
    "        print(\"\\nBuilding author ID mapping in batches...\")\n",
    "        batch_size = 100000\n",
    "        c.execute('SELECT COUNT(*) FROM authors')\n",
    "        total_authors = c.fetchone()[0]\n",
    "        processed = 0\n",
    "        \n",
    "        while processed < total_authors:\n",
    "            c.execute('''\n",
    "                WITH normalized_batch AS (\n",
    "                    SELECT \n",
    "                        id,\n",
    "                        keyname,\n",
    "                        COALESCE(forenames, '') as forenames_clean,\n",
    "                        COALESCE(\n",
    "                            CASE \n",
    "                                WHEN suffix IS NOT NULL AND UPPER(suffix) IN ('JR', 'JR.', 'JR ', 'JUNIOR') THEN 'Jr.'\n",
    "                                WHEN suffix IS NOT NULL AND UPPER(suffix) IN ('I', 'II', 'III', 'IV', 'V') THEN UPPER(suffix)\n",
    "                                ELSE suffix\n",
    "                            END,\n",
    "                            ''\n",
    "                        ) as suffix_clean\n",
    "                    FROM authors\n",
    "                    WHERE rowid > ? AND rowid <= ?\n",
    "                )\n",
    "                INSERT INTO author_id_mapping (old_id, new_id)\n",
    "                SELECT \n",
    "                    nb.id as old_id,\n",
    "                    ca.canonical_id as new_id\n",
    "                FROM normalized_batch nb\n",
    "                JOIN canonical_authors ca ON \n",
    "                    nb.keyname = ca.keyname AND\n",
    "                    nb.forenames_clean = ca.forenames_clean AND\n",
    "                    nb.suffix_clean = ca.suffix_clean\n",
    "            ''', (processed, processed + batch_size))\n",
    "            \n",
    "            processed += batch_size\n",
    "            print(f\"Progress: {min(processed, total_authors)}/{total_authors} authors mapped ({(min(processed, total_authors)/total_authors*100):.1f}%)\")\n",
    "        \n",
    "        # Create index for faster lookups\n",
    "        print(\"Creating index on mapping table...\")\n",
    "        c.execute('CREATE INDEX idx_old_id ON author_id_mapping(old_id)')\n",
    "        \n",
    "        # Print mapping stats and verify coverage\n",
    "        print(\"\\nChecking mapping coverage...\")\n",
    "        c.execute('SELECT COUNT(*) FROM author_id_mapping')\n",
    "        total_mappings = c.fetchone()[0]\n",
    "        print(f\"Total authors: {total_authors}\")\n",
    "        print(f\"Total mappings: {total_mappings}\")\n",
    "        \n",
    "        if total_mappings != total_authors:\n",
    "            c.execute('''\n",
    "                SELECT a.id, a.keyname, a.forenames, a.suffix\n",
    "                FROM authors a\n",
    "                LEFT JOIN author_id_mapping m ON a.id = m.old_id\n",
    "                WHERE m.new_id IS NULL\n",
    "                LIMIT 5\n",
    "            ''')\n",
    "            print(\"\\nSample unmapped authors:\")\n",
    "            for row in c.fetchall():\n",
    "                print(f\"ID {row[0]}: {row[1]}, {row[2]}, {row[3]}\")\n",
    "            raise Exception(f\"Found {total_authors - total_mappings} unmapped authors\")\n",
    "        \n",
    "        # Update paper_authors in batches\n",
    "        print(\"\\nUpdating paper-author links...\")\n",
    "        c.execute('SELECT COUNT(*) FROM paper_authors')\n",
    "        total_links = c.fetchone()[0]\n",
    "        processed = 0\n",
    "        \n",
    "        while processed < total_links:\n",
    "            c.execute('''\n",
    "                UPDATE paper_authors\n",
    "                SET author_id = (\n",
    "                    SELECT new_id\n",
    "                    FROM author_id_mapping\n",
    "                    WHERE old_id = paper_authors.author_id\n",
    "                )\n",
    "                WHERE rowid IN (\n",
    "                    SELECT rowid FROM paper_authors\n",
    "                    LIMIT ? OFFSET ?\n",
    "                )\n",
    "            ''', (batch_size, processed))\n",
    "            \n",
    "            processed += batch_size\n",
    "            print(f\"Progress: {min(processed, total_links)}/{total_links} links updated ({(min(processed, total_links)/total_links*100):.1f}%)\")\n",
    "        \n",
    "        # Verify all paper_authors entries have valid author_ids\n",
    "        print(\"\\nVerifying paper-author links...\")\n",
    "        c.execute('''\n",
    "            SELECT COUNT(*) FROM paper_authors pa\n",
    "            LEFT JOIN author_id_mapping m ON pa.author_id = m.old_id\n",
    "            WHERE m.new_id IS NULL\n",
    "        ''')\n",
    "        orphaned = c.fetchone()[0]\n",
    "        if orphaned > 0:\n",
    "            raise Exception(f\"Found {orphaned} paper-author links that would be orphaned\")\n",
    "        \n",
    "        # Replace authors table with canonical version\n",
    "        print(\"Replacing authors table with deduplicated version...\")\n",
    "        c.execute('DROP TABLE IF EXISTS authors_backup')\n",
    "        c.execute('ALTER TABLE authors RENAME TO authors_backup')\n",
    "        c.execute('''\n",
    "            CREATE TABLE authors (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                keyname TEXT NOT NULL,\n",
    "                forenames TEXT,\n",
    "                suffix TEXT,\n",
    "                UNIQUE(keyname, forenames, suffix)\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        # Insert canonical authors\n",
    "        c.execute('''\n",
    "            INSERT INTO authors (id, keyname, forenames, suffix)\n",
    "            SELECT canonical_id, keyname, forenames, suffix\n",
    "            FROM canonical_authors\n",
    "        ''')\n",
    "        \n",
    "        # Print results\n",
    "        c.execute('SELECT COUNT(*) FROM authors_backup')\n",
    "        authors_before = c.fetchone()[0]\n",
    "        c.execute('SELECT COUNT(*) FROM authors')\n",
    "        authors_after = c.fetchone()[0]\n",
    "        print(f\"\\nCleanup complete:\")\n",
    "        print(f\"Authors before: {authors_before}\")\n",
    "        print(f\"Authors after: {authors_after}\")\n",
    "        print(f\"Duplicates removed: {authors_before - authors_after}\")\n",
    "        \n",
    "        # Cleanup temporary tables\n",
    "        print(\"\\nCleaning up temporary tables...\")\n",
    "        c.execute('DROP TABLE IF EXISTS canonical_authors')\n",
    "        c.execute('DROP TABLE IF EXISTS author_id_mapping')\n",
    "        c.execute('DROP TABLE IF EXISTS authors_backup')\n",
    "        \n",
    "        conn.commit()\n",
    "        print(\"Changes committed successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during cleanup: {str(e)}\")\n",
    "        print(\"Rolling back changes...\")\n",
    "        conn.rollback()\n",
    "        \n",
    "        # Cleanup temporary tables\n",
    "        c.execute('DROP TABLE IF EXISTS canonical_authors')\n",
    "        c.execute('DROP TABLE IF EXISTS author_id_mapping')\n",
    "        \n",
    "        # Restore original authors table if needed\n",
    "        c.execute('SELECT COUNT(*) FROM authors')\n",
    "        if c.fetchone()[0] == 0:\n",
    "            print(\"Restoring authors table from backup...\")\n",
    "            c.execute('DROP TABLE authors')\n",
    "            c.execute('ALTER TABLE authors_backup RENAME TO authors')\n",
    "            conn.commit()\n",
    "            print(\"Original authors table restored\")\n",
    "        raise\n",
    "\n",
    "# Run cleanup if needed\n",
    "cleanup_authors(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Save Database to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp papers.db \"/content/drive/MyDrive/ai-safety-papers/papers.db\"\n",
    "print(\"Database saved to Google Drive at: /ai-safety-papers/papers.db\") "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
